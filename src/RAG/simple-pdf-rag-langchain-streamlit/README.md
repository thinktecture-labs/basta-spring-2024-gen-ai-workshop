# Simple PDF RAG with StreamLit Web UI

## Installation
`pip install -r requirements.txt`

## Run it
`streamlit run chat.py`

## Running a local LLM
Easiest way to run a local LLM is to use LM Studio:
https://lmstudio.ai/

The LLM we use in our conference talks:
- dolphin-2.2.1-mistral-7b.Q8_0
  - https://huggingface.co/TheBloke/dolphin-2.2.1-mistral-7B-GGUF

- Also great is zephyr:7b-beta-q5_K_M
  - https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF
